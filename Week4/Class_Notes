		
#######################
Day 16: 4th August 2025
#######################					
						
	- Kubernetes Architecture!
	- Kubernetes Components 
	- Kubernetes Terminologies/Concepts		

	- Setup Kubernetes-Cluster using kubeadm 
	
	- Create Az-CICD Pipeline using Kubernetes
	
	
		Environments :
		
		
			Dev 
				
			Build 
			
			Target Environments :
			
				QA 
				
				UAT 
				
				Prod 
				
					- Prod_Servers : 1,2,3,4,5
					
		Kubernetes:
		
			Master/Worker_Node 
			
			Kubernetes_Master(VM)			# Controller  
			
				Kubernetes_WorkNode1(VM)
				Kubernetes_WorkNode2(VM)
				Kubernetes_WorkNode3(VM)
				
		Kubernetes Architecture Components :::
		
			- Kubernetes Cluster			# Collection of WorkNodes 
			
			- API Server 
			
			- ETCD 
			
			- Scheduler 
			
			- Controller Manager 
			
			- Kubelet 
			
			- Kube-proxy
			
			- CRI - Container Runtime Interface - Container-D
			
		
			Kubernetes_Master(VM)											#Controller  
				Cluster :													Region1
					Kubernetes_WorkNode1(VM)
					Kubernetes_WorkNode2(VM)
					Kubernetes_WorkNode3(VM)	
				Cluster :													Region2
					Kubernetes_WorkNode1(VM)
					Kubernetes_WorkNode2(VM)
					Kubernetes_WorkNode3(VM)	



			Kubernetes_Master													On-Prem
			
				Kubernetes_Master(VM)			# Controller  					AWS
					Cluster :													Region1
						Kubernetes_WorkNode1(VM)
						Kubernetes_WorkNode2(VM)
						Kubernetes_WorkNode3(VM)	
					Cluster :													Region2
						Kubernetes_WorkNode1(VM)
						Kubernetes_WorkNode2(VM)
						Kubernetes_WorkNode3(VM)	
				
				Kubernetes_Master(VM)			# Controller  					Azure
					Cluster :													Region1
						Kubernetes_WorkNode1(VM)
						Kubernetes_WorkNode2(VM)
						Kubernetes_WorkNode3(VM)	
					Cluster :													Region2
						Kubernetes_WorkNode1(VM)
						Kubernetes_WorkNode2(VM)
						Kubernetes_WorkNode3(VM)
	
			
	- Kubernetes Terminologies/Concepts :::

		- kubectl				# Commmand line utility 
								# Used to interact with Kubernetes_Master
							
		- Pod 					# Is a smallest/Atomic unit of schedule 
								# Pod will be assigned with an IP Address for Networking 
								# A pod can have one or two container definitions
																
		- kubeadm 				# Command line utility to config Kubernetes-Cluster
		
		- Networking 
		
		- volumes 
		
		- Services 
		
			- Cluster-IP Services 
			
			- NodePort Services

			- Load Balancer!
			
			
		- Controller Objects :				# Is used to execute the pods in its desired state.
		
			- Deployment Controller Objects 
				- Deployment Strategies
				
				Continuous Deployment we can achieve Zero-Downtime.
				
				- Rolling Update Strategies :
				
				- Canary Deployment Strategies 
				
				- Blue-Green Strategies
				
					Passive Prod Environments			v1.0 		LIVE 
					
					Active Prod Environments			v2.0		LIVE 
				
				
	Replica : 3 	mywebapp-Img:v1.0			===========>		mywebapp-Img:v2.0
			
		Pod1.1	mywebapp-Img:v1.0							mywebapp-Img:v1.1
		
		Pod1.2	mywebapp-Img:v1.0							mywebapp-Img:v1.1
		
		Pod1.3	mywebapp-Img:v1.0							mywebapp-Img:v1.1
				
		
	Application Architecture :
	
	3 - Tier Application Architecture :		Micro-Service 
	
		- Front-End Layer 			# User Interaction	# Pod1.1,1.2,1.3
		
		- Application Layer 		# Business Logics 	# Pod2.1,2.2,2.3 
		
		- Backend Layer 			# Database 			# Pod3.1,3.2,3.3
			
			
Installation & Configuration of Kubernetes using Kubeadm Utility :::
		https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/
			
			Kubernetes_Master(VM)											
				Cluster :													
					Kubernetes_WorkNode1(VM)
					Kubernetes_WorkNode2(VM)

AKS :
			
			
	About Kubernetes Pods 
	
	- Manifest files :
	
		- *.yaml 
		- *.json 
#######################
Day 17: 5th August 2025
#######################				
		
	Work kubectl Commands 
	
		- Create Manifest file to deploy the service to kubernetes cluster 
		
	Set-up release pipelines!
	
		- Classic Pipelines 
		
	
	IAC Tools :
	
		- Azure Resource Manager/Terraform to Create Az Resources 
		
	
kubectl commands :

		kubectl get nodes
		
		kubectl get pods		# To get the list of pods running in default namespace 
		
		Namespace :				# Logical Partition of Kubernetes-Cluster	
								# Namespaces can be created based on the Environment/Team/Resource Types
								# Can be used to perform blue-green deployments 
		
		
		Target Environments :


			Kubernetes_Master(VM)		Non-Prod 		==> Namespaces : dev/qa/uat								
				Cluster :													
					Kubernetes_WorkNode1(VM)
					Kubernetes_WorkNode2(VM)
					
					
					
			Kubernetes_Master(VM)		Prod_v1.0	LIVE 											
				Cluster :													
					Kubernetes_WorkNode1(VM)
					Kubernetes_WorkNode2(VM) 
		

			
			namespace: webappv1
			
			namespace: webappv2
			
			
			File system:
			
				c: 
					OS_Folder 		--> OS Files 							kube-system 
					
					Folder1 		-- Logical entity - Source_code 		dev 
						- files 						
					Folder2 		-- Logical entity - docs 				qa 
						- files 	

		Namespaces :
		
			- kubectl create namespace dev 
			
		
		How to create Pods!
		
			- Create Manifest files 
			
				*.yaml
				
				
		Deployment Controller Objects ::

	Controller Object :::
		ReplicaSet 
		Deployment 


	ReplicaSet :::
	
		--> Replicaset is used to execute the specific no. of pods in the cluster.
		--> Replicaset uses the Set Based Operator
		--> Used to replicate the pods and able to scale up/down
		--> The Replicasets will be automatically created, while creating Deployment Controller Object.
	
	Deployment Controller Object :::
	
		--> It is used to deploy the pods and ensure high availability of pods by creating pod replicas 
		--> 1. Create Muliple instance/replicas/copies of pods 
			2. Used to Scale-Up / Scale-Down the Pods 
			3. Used to Upgrade the application pods 
			4. Used to Down-grade/roll-back the application pods
		--> The upgrade/down-grade of application pods can be done without any downtime. 
		--> To achieve zero-downtime during upgrade/down-grade, By Default, it used Rolling-Update Deployment Strategy.
		
		
		webappV1 	==> 	pod1,2,3 
		
		
		-> Deployment 
		
		-> ReplicaSet
		
		-> Pod instances 

Manifest file to Create Deployment Controller :
	
apiVersion: apps/v1
kind: Deployment
metadata:
  name: loksai-eta-deploy
  labels:
    app: loksai-eta-deploy-lbl
spec:
  replicas: 3
  selector:
    matchLabels:
      app: loksai-eta-app
  template:
    metadata:
      labels:
        app: loksai-eta-app
    spec:
      containers:
      - name: loksai-eta-container
        image: loksaieta/skazwebapp
        ports:
        - containerPort: 8080
---
apiVersion: v1
kind: Service
metadata:
  name: loksai-eta-np-service
  labels:
    app: loksai-eta-app
spec:
  selector:
    app: loksai-eta-deploy-lbl

  type: NodePort
  ports:
  - nodePort: 31028
    port: 8080
    targetPort: 8080	


		# NodePort Rage : 30000 - 32767
		# NodePort Service is used to expose the pods to internet!
		
		
		<external_ip_addr>:<node_port>
		
		Nodeport is mapped with pod 
		
		
	Kubernetes Services :
	
		- NodePort 
		
		- LoadBalancer
		
			- Create LB at application level 
			- Route the request to service.
			
			
		- Ingress Controller Rules :
		
			- Simple Routing 			# Web Page - static Web-Page 	www.loksai-ai-blog.com
			
			- Host Based Routing 
			
			- Path Based Routing 
			
		
		www.google.com 				Load Balancer @ Application Level 
		
			Maps 	:	www.maps.google.com 										Host Based Routing 
			
			Drive 	:	www.drive.google.com
			
			Email 	: 	www.mail.google.com
		
			
		www.mail.google.com
		
			inbox 		: www.gmail.com/inbox 										Path Based Routing 
			
			sent 
			
			trash 
			
		
	kubectl describe deploy loksai-eta-deploy	
	
	kubectl scale deployment loksai-eta-deploy --replicas=10
	
	Horizontal Scaling 			: Scale up/Down - no. of pods --> 50 			==> HPA 
	
	Vertical Scaling 			: Scale up/Down - no. of Nodes 					==> VPA 
	
	
	kubectl top pod 			# Metrics Server ! Metrics APIs 
	
	kubectl top pod -n qa 		# At Namespace level 
	
		- Service Connection 
		
Next :

	Integrate Target Envionments to Az Pipelines :
	
		- Web Apps Server 				# Deploy the Application Artifacts - Non-Containerized workloads 
		
		- Kubernetes-Cluster			# Deploy the Application Images -	Containerized workloads 
			- AKS 
			- On-prem 
		
	IAC 
		
#######################
Day 18: 5th August 2025
#######################						
			
	Integrate Target Envionments to Az Release Pipelines :
	
		- Web Apps Server 				# Deploy the Application Artifacts - Non-Containerized workloads 
		
		
		Configuration of WebApp Server!
		
			- Target Envionments for any Application Deployments :
			
				- Azure Managed Deployments Servers 
				
					
		
	IAC Tools :
	
		ARM - Terraform Scripts :
		
	Monitoring :
	
		- Cloud Resource Monitor using Azure Monitor 
		
			- Threshold limit :
			
				70% of CPU Utilization 
					- Alert Managers to setup the automated Notifications 
					- Scale the resources 
		
		- Kubernetes Monitoring!
		
			Auto Scaling 
			
				- CPU / Memory 
				
				- Monitor the Pods 
				
				- helm charts to setup the monitoring tools like prometheus/grafana
				
					- Create Kubernetes Dashboards to Monitor the Pods and Deployment Objects 
			
			
			
			Non-Prod 
			
				unit testing 
				
				unit test coverage 
				
				==> QA 
				
					QA testing 
					
					QA coverage 
					
					==> Prod 
						
							ServiceNow 
							
								Change Order 
								
									Approve CO 
									
									Release Gates :
									
										-> APIs -- pre-check all the quality gates 
										
										-> GreenLight-API --> GLAPI
			
			
	Azure Monitor :

		- Az Resources :
		
	Azure Monitor/Dynatrace/Splunk/Nagios/Prometheus/
	
	Grafana :
	
		- Visualization Tool
		- Used to prepare dashboards 
		
	Architecture of Monitoring Servers :
	
			- Azure Monitor/Dynatrace/Splunk/Nagios/Prometheus/
		
		
	IAC Tools ::
			
			Azure Resource Manager 
			
			Terraform Script to invoke the ARM to create the resources. 
			
			
			IAC Tools :
			
				Provision/Create Resources 	- AzRM / Terraform 
				
				Configuration Management 	- Ansible/Chef/Puppet
				
				
		az cli ==> create the resources 
		
		
		Scripting Languages! 
		
		*.sh
		
			-- create resource group
			-  create vm 
			-  install the required tools 


		-> Identify the Infra-Structure 
		-> Write the IAC Terraform Script 
		-> Perform Terraform Init 			# Initialize Terraform Registry for Azure - Download the Azure Provider
		-> Perform Terraform Plan 			# Preview the Terraform Script 
		-> Perform Terraform Apply 			# Create/Update the Resources in Target
		
		
			Terraform Registry 
			
				https://registry.terraform.io/browse/providers
		
		
		- Visual Studio Code to create the Terraform Scripts 
		
			- Azure Subscription 			bf1aeccd-85bd-4d70-a583-65f6c8f7a4cb
			
			- Azure Tenant ID 				513ba6a2-5057-4c96-8ef0-fea57eaf9e80
			
			Create App Registration : 
			
			- Azure Client ID 				90eca237-f144-48fb-8c70-a3286580b196
			- Azure Client Secret 			165c3193-0a79-4f85-8d82-e8406d37cd35
			
